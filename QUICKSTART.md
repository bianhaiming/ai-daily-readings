# ğŸš€ AI æ¯æ—¥æ·±åº¦é˜…è¯» - GLM-4.7 é›†æˆå®Œæˆ

---

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

### 1. **NVIDIA å®¢æˆ·ç«¯** (`llm/nvidia_client.py`)
- âœ… æ”¯æŒ GLM-4.7 æ¨¡å‹ï¼ˆ`z-ai/glm4.7`ï¼‰
- âœ… è‡ªåŠ¨è¯†åˆ« GLM æ¨¡å‹å¹¶å¤„ç†ç‰¹æ®Šå“åº”æ ¼å¼
- âœ… ä» `reasoning_content` æå–æœ€ç»ˆç­”æ¡ˆ
- âœ… æ·»åŠ  `system_prompt` æ”¯æŒ
- âœ… æ”¯æŒå¤šç§ JSON æå–æ–¹å¼

### 2. **é…ç½®æ–‡ä»¶** (`config/sources.json`)
- âœ… æ·»åŠ  `nvidia_model` é…ç½®é¡¹
- âœ… é»˜è®¤ä½¿ç”¨ `z-ai/glm4.7` æ¨¡å‹

### 3. **ä¸»ç¨‹åº** (`main.py`)
- âœ… ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹åç§°
- âœ… åˆ›å»ºå®¢æˆ·ç«¯æ—¶ä¼ é€’æ¨¡å‹å‚æ•°

---

## ğŸ“‹ å¯ç”¨çš„ NVIDIA æ¨¡å‹

| æ¨¡å‹ | é…ç½®å€¼ | è¯´æ˜ |
|-----|---------|------|
| **GLM-4.7** | `z-ai/glm4.7` | ğŸ¯ å½“å‰é»˜è®¤ï¼Œæ€ç»´é“¾æ¨¡å‹ |
| Llama 3.1 70B | `meta/llama-3.1-70b-instruct` | é€šç”¨æ¨¡å‹ |
| Llama 3.1 8B | `meta/llama-3.1-8b-instruct` | è¾ƒå¿«ä½†èƒ½åŠ›è¾ƒå¼± |
| Mistral Large | `mistralai/mistral-large` | é«˜è´¨é‡æ¨¡å‹ |

### åˆ‡æ¢æ¨¡å‹

**ç¼–è¾‘ `config/sources.json`:**

```json
{
  "nvidia_model": "meta/llama-3.1-70b-instruct"
}
```

---

## ğŸ¯ GLM-4.7 æ¨¡å‹ç‰¹ç‚¹

### âœ… ä¼˜åŠ¿
- **æ€ç»´é“¾èƒ½åŠ›å¼º**ï¼šæä¾›å®Œæ•´çš„æ¨ç†è¿‡ç¨‹
- **ä¸­æ–‡æ”¯æŒä¼˜ç§€**ï¼šç†è§£ä¸­æ–‡æŒ‡ä»¤å’Œç”Ÿæˆä¸­æ–‡å†…å®¹
- **JSON è¾“å‡ºç¨³å®š**ï¼šå¯ä»¥ç”Ÿæˆæ ¼å¼åŒ–çš„ JSON
- **å…è´¹é¢åº¦å……è¶³**ï¼šNVIDIA å…è´¹é¢åº¦æ”¯æŒå¤§é‡è°ƒç”¨

### âš ï¸ ç‰¹æ®Šè¡Œä¸º
GLM-4.7 ä½¿ç”¨ `reasoning_content` å­—æ®µå­˜å‚¨æ€è€ƒè¿‡ç¨‹ï¼š
- `content` å­—æ®µå¯èƒ½ä¸º `null`
- æœ€ç»ˆç­”æ¡ˆå¯èƒ½åœ¨ `reasoning_content` ä¸­
- éœ€è¦ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–æœ€ç»ˆç­”æ¡ˆ

**ä»£ç å·²è‡ªåŠ¨å¤„ç†è¿™äº›ç‰¹æ®Šæƒ…å†µï¼**

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æµ‹è¯•é›†æˆ

```bash
cd /Users/bianhaiming/ai-daily-readings

# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
python3 -m pip install -r requirements.txt

# è®¾ç½® API Keyï¼ˆä½¿ç”¨ä½ çš„ NVIDIA Keyï¼‰
export NVIDIA_API_KEY="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"

# æµ‹è¯•è¯„åˆ†
python3 -c "
from llm.nvidia_client import NvidiaClient
client = NvidiaClient()
article = {'title': 'Test', 'summary': 'This is a test', 'source': 'test', 'published': '2025-12-15'}
result = client.score_article(article)
print(f'Score: {result[\"score\"]}')
print(f'Recommended: {result[\"recommended\"]}')
"
```

### 2. è¿è¡Œå®Œæ•´è„šæœ¬

```bash
# æ–¹å¼ 1ï¼šæ‰‹åŠ¨è¿è¡Œ
python3 main.py

# æ–¹å¼ 2ï¼šé€šè¿‡ GitHub Actionsï¼ˆéœ€è¦å…ˆæ¨é€ workflowï¼‰
# è®¿é—® Actions é¡µé¢ï¼Œç‚¹å‡» "Run workflow"
```

### 3. æ¨é€åˆ° GitHub

```bash
# æäº¤ä¿®æ”¹
git add .
git commit -m "Integrate GLM-4.7 model support"

# æ¨é€ï¼ˆå‡è®¾ä½ å·²ç™»å½•å¹¶æˆæƒï¼‰
git push origin main
```

---

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

| ç‰¹æ€§ | GLM-4.7 | Llama 3.1 70B |
|-----|---------|------------------|
| **æ€ç»´é“¾** | âœ… è¯¦ç»†æ¨ç† | âš ï¸ ç®€å•æ¨ç† |
| **ä¸­æ–‡èƒ½åŠ›** | âœ… ä¼˜ç§€ | âœ… è‰¯å¥½ |
| **æ¨ç†å‡†ç¡®æ€§** | âœ… æ›´é«˜ | âœ… é«˜ |
| **å“åº”é€Ÿåº¦** | âš ï¸ ç¨æ…¢ï¼ˆéœ€è¦æ¨ç†ï¼‰ | âœ… è¾ƒå¿« |
| **JSON è¾“å‡º** | âœ… ç¨³å®š | âœ… ç¨³å®š |
| **é€‚ç”¨åœºæ™¯** | å¤æ‚æ–‡ç« è¯„åˆ†ã€æ·±åº¦åˆ†æ | å¿«é€Ÿæ‘˜è¦ã€åˆ†ç±» |

---

## ğŸ”§ é«˜çº§é…ç½®

### ä½¿ç”¨ system_prompt

```python
from llm.nvidia_client import NvidiaClient

client = NvidiaClient(model="z-ai/glm4.7")

response = client.chat(
    prompt="å¸®æˆ‘åˆ†æè¿™æ®µä»£ç ",
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä»£ç åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºæ€§èƒ½ä¼˜åŒ–..."
)
```

### è°ƒæ•´è¯„åˆ†æ ‡å‡†

ç¼–è¾‘ `config/sources.json`:

```json
{
  "minimum_score": 7.5,
  "daily_limit": 8
}
```

---

## ğŸ“ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šJSON è§£æå¤±è´¥

**ç°è±¡ï¼š**
```
Failed to parse JSON response: ...
```

**è§£å†³æ–¹æ³•ï¼š**
1. GLM-4.7 å¯èƒ½è¿”å›é¢å¤–æ–‡å­—ï¼Œå·²è‡ªåŠ¨å¤„ç†
2. æ£€æŸ¥ `reasoning_content` ä¸­æ˜¯å¦åŒ…å«å®Œæ•´ JSON
3. å°è¯•é™ä½ `temperature` å‚æ•°

### é—®é¢˜ 2ï¼šè¯„åˆ†ä¸å‡†ç¡®

**è§£å†³æ–¹æ³•ï¼š**
1. è°ƒæ•´ `minimum_score` é˜ˆå€¼
2. ä¿®æ”¹è¯„åˆ† prompt çš„æƒé‡
3. æ·»åŠ ç¤ºä¾‹æé«˜ç†è§£

### é—®é¢˜ 3ï¼šGLM å“åº”ä¸ºç©º

**æ£€æŸ¥ï¼š**
1. API Key æ˜¯å¦æ­£ç¡®
2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **GLM-4.7 é›†æˆè¯¦æƒ…**ï¼š`GLM4_INTEGRATION.md`
- **éƒ¨ç½²è¯´æ˜**ï¼š`DEPLOYMENT.md`
- **README**ï¼š`README.md`

---

## ğŸ‰ ä¸‹ä¸€æ­¥

### ç«‹å³è¡ŒåŠ¨

1. **æµ‹è¯•å½“å‰é…ç½®**
   ```bash
   cd /Users/bianhaiming/ai-daily-readings
   python3 main.py
   ```

2. **æ¨é€åˆ° GitHub**
   ```bash
   git add .
   git commit -m "Integrate GLM-4.7 model"
   git push origin main
   ```

3. **æ·»åŠ  GitHub Actions workflow**ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
   - å‚è€ƒ `DEPLOYMENT.md` ä¸­çš„è¯´æ˜
   - æˆ–è¿è¡Œ `bash deploy.sh`

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### æœ€ä½³å®è·µ

1. **GLM-4.7 é€‚ç”¨åœºæ™¯**
   - éœ€è¦æ·±åº¦æ¨ç†çš„æ–‡ç« è¯„åˆ†
   - å¤æ‚å†…å®¹åˆ†æ
   - éœ€è¦æ€è€ƒè¿‡ç¨‹çš„åœºæ™¯

2. **Llama 3.1 é€‚ç”¨åœºæ™¯**
   - å¿«é€Ÿæ‘˜è¦ç”Ÿæˆ
   - ç®€å•åˆ†ç±»ä»»åŠ¡
   - è¿½æ±‚é€Ÿåº¦çš„åœºæ™¯

3. **æ¸©åº¦å‚æ•°å»ºè®®**
   - è¯„åˆ†ä»»åŠ¡ï¼š`temperature=0.1`ï¼ˆæ›´ç¡®å®šï¼‰
   - æ‘˜è¦ç”Ÿæˆï¼š`temperature=0.5`ï¼ˆæœ‰ä¸€å®šåˆ›é€ æ€§ï¼‰
   - å¯¹è¯ï¼š`temperature=0.7`ï¼ˆæ›´è‡ªç„¶ï¼‰

---

**ğŸŠ GLM-4.7 å·²æˆåŠŸé›†æˆåˆ° AI æ¯æ—¥æ·±åº¦é˜…è¯»å·¥å…·ï¼**

äº«å—æ›´å¼ºå¤§çš„ AI æ¨èä½“éªŒå§ï¼
