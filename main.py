import os
import json
from datetime import datetime
from fetchers.github_fetcher import GitHubFetcher
from fetchers.twitter_fetcher import TwitterFetcher
from fetchers.arxiv_fetcher import ArxivFetcher
from fetchers.blog_fetcher import BlogFetcher
from fetchers.hackernews_fetcher import HackerNewsFetcher
from llm.nvidia_client import NvidiaClient
from filters.article_filter import ArticleFilter
from generators.issue_generator import IssueGenerator
import requests


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(os.path.dirname(__file__), 'config', 'sources.json')

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ AI æ¯æ—¥æ¨èå·¥å…·...")

    config = load_config()
    sources_config = config['sources']
    llm_provider = config.get('llm_provider', 'nvidia')

    print(f"ğŸ“Š LLM Provider: {llm_provider}")

    llm_client = NvidiaClient()
    article_filter = ArticleFilter(config, llm_client)
    issue_generator = IssueGenerator()

    all_articles = []
    source_stats = {}

    print("\nğŸ“¡ ä»å„æ•°æ®æºè·å–å†…å®¹...")

    for source_name, source_config in sources_config.items():
        if not source_config.get('enabled', False):
            continue

        print(f"\nğŸ” å¤„ç† {source_name}...")

        try:
            if source_name == 'github':
                fetcher = GitHubFetcher(source_config['config'])
                articles = fetcher.fetch_trending()

            elif source_name == 'twitter':
                fetcher = TwitterFetcher(source_config['config'])
                articles = fetcher.fetch_all()

            elif source_name == 'arxiv':
                fetcher = ArxivFetcher(source_config['config'])
                articles = fetcher.fetch_papers()

            elif source_name == 'blogs':
                fetcher = BlogFetcher(source_config)
                articles = fetcher.fetch_articles()

            elif source_name == 'hackernews':
                fetcher = HackerNewsFetcher(source_config['config'])
                articles = fetcher.fetch_stories()

            else:
                articles = []

            source_stats[source_name] = {
                'fetched': len(articles),
                'filtered': 0,
                'selected': 0
            }

            print(f"  âœ“ è·å–äº† {len(articles)} ç¯‡æ–‡ç« ")

            if articles:
                filtered = article_filter.filter_articles(articles)
                source_stats[source_name]['filtered'] = len(filtered)

                daily_limit = source_config.get('daily_limit', 1)
                selected = article_filter.select_top_articles(filtered, daily_limit)
                source_stats[source_name]['selected'] = len(selected)

                print(f"  âœ“ AI è¿‡æ»¤å: {len(filtered)} ç¯‡")
                print(f"  âœ“ æœ€ç»ˆæ¨è: {len(selected)} ç¯‡")

                all_articles.extend(selected)

        except Exception as e:
            print(f"  âŒ å¤„ç† {source_name} æ—¶å‡ºé”™: {e}")
            source_stats[source_name] = {
                'fetched': 0,
                'filtered': 0,
                'selected': 0
            }

    print(f"\nğŸ“ æ€»å…±è·å–äº† {len(all_articles)} ç¯‡æ¨èæ–‡ç« ")

    if all_articles:
        print("\nğŸ¤– ç”Ÿæˆæ‘˜è¦å’Œåˆ†ç±»...")
        all_articles = article_filter.add_summaries(all_articles)
        all_articles = article_filter.classify_articles(all_articles)

        print("\nğŸ“„ ç”Ÿæˆ GitHub Issue...")
        issue_content = issue_generator.generate_issue(all_articles, source_stats)

        print(issue_content)

        print("\nâœ… Issue å†…å®¹ç”Ÿæˆå®Œæˆï¼")

        if os.environ.get('GITHUB_TOKEN'):
            print("\nğŸ“¤ åˆ›å»º GitHub Issue...")
            create_github_issue(issue_content)
        else:
            print("\nâš ï¸  GITHUB_TOKEN æœªè®¾ç½®ï¼Œè·³è¿‡åˆ›å»º Issue")

    else:
        print("\nâŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ç« è¢«æ¨è")


def create_github_issue(content: str):
    """åˆ›å»º GitHub Issue"""
    repo = os.environ.get('GITHUB_REPOSITORY', 'bianhaiming/ai-daily-readings')
    token = os.environ.get('GITHUB_TOKEN')

    if not token:
        print("âŒ GITHUB_TOKEN æœªè®¾ç½®")
        return

    title = f"ğŸ“– æ¯æ—¥æ·±åº¦é˜…è¯» - {datetime.now().strftime('%Y-%m-%d')}"

    url = f"https://api.github.com/repos/{repo}/issues"

    headers = {
        'Authorization': f'token {token}',
        'Content-Type': 'application/json'
    }

    payload = {
        'title': title,
        'body': content,
        'labels': ['daily-reading', 'ai']
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()

        issue_url = response.json()['html_url']
        print(f"âœ… Issue åˆ›å»ºæˆåŠŸ: {issue_url}")

    except requests.exceptions.RequestException as e:
        print(f"âŒ åˆ›å»º Issue å¤±è´¥: {e}")


if __name__ == '__main__':
    main()
